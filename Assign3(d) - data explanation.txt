CS 4F03 Assign 3,part d

- openMP has a consistent speedup with adding processes.
- openMP's efficiency gradually levels off with adding threads because there is a serial time associated with allocating the "iterations" array memory, some small initializaiton task, and the time it takes to fork new threads.
- The performance improves fairly consistently when adding new threads, since we made sure to evenly distribute the computational load among threads. We don't have any threads doing much more work than any others. 
- When we performance stested only the parallel sections without any serial sections, the code scaled very well, almost 1:1 with the numer of threads. 

- openACC code was faster, since the code is highly parallelizable and the GPUs are a good fit for performing those calculations.
- The openACC double precision rate was about 1/4 or 1/3 of the single precision rate, which is consistent with the rate of many Nvidia professional GPUs.
-There were no large data transferring between the main memory and GPU memory during the calculations of iterations. All larege memory transfers occur before and after the calculations, greatly improving performance by making the performance compute bound rather than memory bound. 

- Because of the parallelizability of the code and performance with GPUs, and the fact that it takes ~ 16-32 CPU cores to reach the same performance, it is very advantageous to write code that utilizes GPUs. 